{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Transformer from scratch~\n",
    "\n",
    "\n",
    "#1. Positional Encoding\n",
    "#2. Multi-Head Attention\n",
    "#3. Feed Forward Network\n",
    "#4. Encoder Layer\n",
    "#5. Decoder Layer\n",
    "#6. Encoder\n",
    "#7. Decoder\n",
    "#8. Transformer\n",
    "\n",
    "#1. Positional Encoding\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.pe = torch.zeros(max_seq_len, d_model)\n",
    "        \n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                self.pe[pos, i] = np.sin(pos/(10000**(i/d_model)))\n",
    "                self.pe[pos, i+1] = np.cos(pos/(10000**((i+1)/d_model)))\n",
    "\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "    \n",
    "#2. Multi-Head Attention\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.linear_q = torch.nn.Linear(d_model, d_model)\n",
    "        self.linear_k = torch.nn.Linear(d_model, d_model)\n",
    "        self.linear_v = torch.nn.Linear(d_model, d_model)\n",
    "        self.linear_final = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        #perform linear operation and split into h heads\n",
    "        k = self.linear_k(k).view(bs, -1, self.n_heads, self.d_k)\n",
    "        q = self.linear_q(q).view(bs, -1, self.n_heads, self.d_k)\n",
    "        v = self.linear_v(v).view(bs, -1, self.n_heads, self.d_k)\n",
    "\n",
    "        #transpose to get dimensions bs * n_heads * seq_len * d_k\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = self.attention(q, k, v, self.d_k, mask)\n",
    "\n",
    "        #concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.linear_final(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def attention(self, q, k, v, d_k, mask=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) /  np.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "#3. Feed Forward Network\n",
    "class FeedForwardNetwork(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(d_model, d_ff)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.linear_2 = torch.nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(torch.nn.functional.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "#4. Encoder Layer\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm_2 = torch.nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ff = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.dropout_1 = torch.nn.Dropout(dropout)\n",
    "        self.dropout_2 = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        src2 = self.norm_1(src)\n",
    "        src = src + self.dropout_1(self.attn(src2, src2, src2, mask))\n",
    "        src2 = self.norm_2(src)\n",
    "        src = src + self.dropout_2(self.ff(src2))\n",
    "        return src\n",
    "\n",
    "#5. Decoder Layer\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm_2 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm_3 = torch.nn.LayerNorm(d_model)\n",
    "        self.attn_1 = MultiHeadAttention(d_model, n_heads)\n",
    "        self.attn_2 = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ff = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.dropout_1 = torch.nn.Dropout(dropout)\n",
    "        self.dropout_2 = torch.nn.Dropout(dropout)\n",
    "        self.dropout_3 = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        trg2 = self.norm_1(trg)\n",
    "        trg = trg + self.dropout_1(self.attn_1(trg2, trg2, trg2, trg_mask))\n",
    "        trg2 = self.norm_2(trg)\n",
    "        trg = trg + self.dropout_2(self.attn_2(trg2, enc_src, enc_src, src_mask))\n",
    "        trg2 = self.norm_3(trg)\n",
    "        trg = trg + self.dropout_3(self.ff(trg2))\n",
    "        return trg\n",
    "\n",
    "#6. Encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, d_model, n_heads, d_ff, n_layers, dropout, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.tok_embedding = torch.nn.Embedding(input_dim, d_model)\n",
    "        self.pos_embedding = PositionalEncoding(d_model, max_seq_len)\n",
    "        self.layers = torch.nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        src = self.dropout((self.tok_embedding(src) * np.sqrt(self.d_model)) + self.pos_embedding(src))\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, mask)\n",
    "        return src\n",
    "\n",
    "#7. Decoder\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, d_model, n_heads, d_ff, n_layers, dropout, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.tok_embedding = torch.nn.Embedding(output_dim, d_model)\n",
    "        self.pos_embedding = PositionalEncoding(d_model, max_seq_len)\n",
    "        self.layers = torch.nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        trg = self.dropout((self.tok_embedding(trg) * np.sqrt(self.d_model)) + self.pos_embedding(trg))\n",
    "        for layer in self.layers:\n",
    "            trg = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        return trg\n",
    "\n",
    "#8. Seq2Seq\n",
    "class Seq2Seq(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg != 0).unsqueeze(1).unsqueeze(2)\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool()\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rui\\Documents\\GitHub\\NLP\\trasnformers_from_scratcb\\experiment.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rui/Documents/GitHub/NLP/trasnformers_from_scratcb/experiment.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#import tokenizer and dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rui/Documents/GitHub/NLP/trasnformers_from_scratcb/experiment.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rui/Documents/GitHub/NLP/trasnformers_from_scratcb/experiment.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvocab\u001b[39;00m \u001b[39mimport\u001b[39;00m build_vocab_from_iterator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "#TEST transformer\n",
    "\n",
    "#1. Load data\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "#import data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6222f30a04324eb0e1388dd9d92114e7e65302edf73019a41583b5b5a3ccc776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
